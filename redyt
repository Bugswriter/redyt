#!/bin/sh

# Check if necessary programs are installed
for prog in dmenu jq sxiv; do
	[ ! "$(which "$prog")" ] && echo "Please install $prog!" && exit 1
done
# If notify-send is not installed, use echo as notifier
[ ! "$(which notify-send)" ] && notifier="echo" || notifier="notify-send"

# Default config directory
configdir="${XDG_CONFIG_HOME:-$HOME/.config}/redyt"

# Create .config/redyt if it does not exist to prevent
# the program from not functioning properly
[ ! -d "$configdir" ] && echo "Directory $configdir does not exist, creating..." && mkdir -p "$configdir"

# Default subreddit that will be inserted in "subreddit.txt"
# if it does not exist
defaultsub="linuxmemes"

# If subbreddit.txt does not exist, create it to prevent
# the program from not functioning properly
[ ! -f "$configdir/subreddit.txt" ] && echo "$defaultsub" >> "$configdir/subreddit.txt"

# If no argument is passed
if [ -z "$1" ]; then
	# Ask the user to enter a subreddit
	subreddit=$(dmenu -p "Select Subreddit r/" -i -l 10 < "$configdir/subreddit.txt" | cut -d\| -f1 | awk '{$1=$1;print}')

	# If no subreddit was chosen, exit
	[ -z "$subreddit" ] && exit 1

# Otherwise assign the first argument to the
# subreddit variable
else
	subreddit="$1"
fi

# Default directory used to store the feed file and fetched images
cachedir="/tmp/redyt"

# If cachedir does not exist, create it
if [ ! -d "$cachedir" ]; then
	echo "$cachedir does not exist, creating..."
	mkdir -p "$cachedir"
fi

# Limit the maximum number of requests to make
limit=100

# Send a notification
$notifier "Redyt" "ðŸ“© Downloading your ðŸ–¼ï¸ Memes"

# Set user agent
$useragent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"

# Download the subreddit feed, containing only the
# first 100 entries (limit), and store it inside
# cachedir/tmp.json
curl -H "User-agent: '$useragent'" "https://www.reddit.com/r/$subreddit/hot.json?limit=$limit" > "$cachedir/tmp.json"


# Create a list of images
imgs=$(jq '.' < "$cachedir/tmp.json" | grep url_overridden_by_dest | grep -Eo "http(s|)://.*(jpg|png)\b" | sort -u)

# If there are no images, exit
[ -z "$imgs" ] && $notifier "Redyt" "sadly, there are no images for subreddit $subreddit, please try again later!" && exit 1

# Download images to $cachedir
wget -P "$cachedir" $imgs

# Send a notification
$notifier  "Redyt" "ðŸ‘ Download Finished, Enjoy! ðŸ˜Š"

# Display the images
sxiv -a "$cachedir"/*.png "$cachedir"/*.jpg

# Once finished, remove all of the cached images
rm "${cachedir:?}"/*
